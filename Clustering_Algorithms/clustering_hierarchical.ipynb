{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algorithms - Hierarchical Clustering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical clustering** determines cluster assignments by building a hierarchy. This is implemented by either a bottom-up or a top-down approach:\n",
    "\n",
    "- **Agglomerative clustering** is the bottom-up approach. It merges the two points that are the most similar until all points have been merged into a single cluster.\n",
    "\n",
    "- **Divisive clustering** is the top-down approach. It starts with all points as one cluster and splits the least similar clusters at each step until only single data points remain.\n",
    "\n",
    "These methods produce a tree-based hierarchy of points called a **dendrogram**. Similar to partitional clustering, in hierarchical clustering the number of clusters (k) is often predetermined by the user. Clusters are assigned by cutting the dendrogram at a specified depth that results in k groups of smaller dendrograms.\n",
    "\n",
    "Unlike many partitional clustering techniques, hierarchical clustering is a **deterministic** process, meaning cluster assignments won’t change when you run an algorithm twice on the same input data.\n",
    "\n",
    "The **strengths** of hierarchical clustering methods include the following:\n",
    "\n",
    "- They often reveal the finer details about the relationships between data objects.\n",
    "- They provide an interpretable dendrogram.\n",
    "\n",
    "The **weaknesses** of hierarchical clustering methods include the following:\n",
    "\n",
    "- They’re computationally expensive with respect to algorithm complexity.\n",
    "- They’re sensitive to noise and outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative clustering algorithm\n",
    "\n",
    "### Rationale\n",
    "Agglomerative clustering is based on the principle of merging the most similar pairs of clusters at each iteration, until all data points are merged into a single cluster. The similarity between two clusters is typically defined in terms of a distance metric, such as Euclidean distance or cosine similarity, which measures how similar or dissimilar two clusters are based on the distances between their data points.\n",
    "\n",
    "The agglomerative clustering algorithm starts by treating each data point as a single-element cluster, and then proceeds to iteratively merge the most similar pairs of clusters until all data points belong to a single cluster. At each iteration, the algorithm computes the pairwise distances between all remaining clusters and identifies the two closest clusters based on some similarity measure. These two clusters are then merged into a new cluster, which is added to the list of clusters. The algorithm continues to merge the most similar pairs of clusters until there is only one cluster left.\n",
    "\n",
    "The resulting dendrogram provides a hierarchical representation of the data, where the leaves of the dendrogram correspond to the individual data points, and the internal nodes correspond to clusters that are formed by merging the most similar pairs of clusters. The height of each internal node in the dendrogram represents the distance between the two clusters that were merged to form the node. Therefore, the dendrogram can be used to visualize the hierarchical relationships between the clusters and to identify patterns and structures in the data.\n",
    "\n",
    "Agglomerative clustering has several advantages over other clustering algorithms. For example, it can handle non-convex and irregularly shaped clusters, it does not require the specification of the number of clusters in advance, and it can be easily extended to handle large datasets. However, agglomerative clustering can be computationally expensive, especially when the number of data points is large, and it can be sensitive to the choice of distance metric and linkage criterion.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "For our implemenetation of this algorithm, we need to define how to compute the distance D(C<sub>new</sub>, C) between a newly formed cluster C<sub>new</new> and each old cluster C.\n",
    "\n",
    "- Method 1: **Minimum**\n",
    "    One commonly used approach defines the distance between clusters C<sub>1</sub> and C<sub>2</sub> as the smallest distance between any pair of elements from these clusters.\n",
    "\n",
    "    D<sub>min</sub>(C1,C2) = min<sub>all points i in cluster C1, all points j in cluster C2</sub>D<sub>i,j</sub>.\n",
    "\n",
    "- Method 2: **Average**\n",
    "    The distance function that is encountered in the unweighted pair group method with arithmetic mean (UPGMA) algorithm  uses the average distance between elements in two clusters.\n",
    "\n",
    "    $$\n",
    "        D_\\text{avg}(C_1, C_2) = \\dfrac{\\sum_{\\text{all points }i\\text{ in cluster }C_1} ~\\sum_{\\text{all points }j\\text{ in cluster }C_2} D_{i,j}}{|C_1| \\cdot |C_2|}\n",
    "    $$\n",
    "\n",
    "\n",
    "Let's implement it in Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resources**:\n",
    "\n",
    "- [K-Means Clustering in Python: A Practical Guide, by Kevin Arvai](https://realpython.com/k-means-clustering-python/#reader-comments)\n",
    "- [Github repo with functions written from scratch](https://github.com/egeulgen/Bioinformatics_Textbook_Track/tree/7d0109aeffeab0b4b38faff75879cdaabb5c0198)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
